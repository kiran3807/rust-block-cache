# rust-block-cache
Take home project to simulate a HTTP block-cache-service used filter out HTTP clients, with the original block file generated by another external service


## Assumptions :

### Shape of the final solution:

I interpret the following line from the problem statement:

 *Your task is to implement a block cache in Rust with the following public
signature:* 

as to mean, that I am to expose the block cache as a **library** for external use, whether within a service or otherwise.

Hence I make no assumptions about the run times in which the library may be used. Which rules out the usage of tokio for async operations within the library.

An alternative implementation could be to abstract the block-cache as another mircoservice with it's own IP address which other services access either through a REST/RPC end points.

### Block Heirarchy Logic :

* If you have a IP-address and user agent combination occouring twice with different fine grained blocks, the latest entry within the block file wins.

* You can never have an entry where there is only user-agent, or just user-agent and fine grained block combination. The broadest block that can be applied exists only on IP level.

### Data access patterns :

* **High reads** for ```get_blocks``` with short payloads  : 5k reads per second, 20k peak
* **Low volume** of reads for the reading blockfile with a significant larger payload every 5 seconds.

**Number of reads** : This based on the fact that typical enterprise points of presence often handle 100k requests /second or more however it is distributed over multiple services. Hence 5k as lower limit and 20k as upper limit.

**Size of the blockfile** : Based on assumption that edge nodes/caches typically favour data-structures that can be fit within the memory without taxing the node, I assume it's max size will shoot up to a million rows, with 50-100bytes per line. 

Which implies in memory at worst it would not exceed 400-500MB and thus can be handled by modern devices.



## Solution : 

A library crate that will expose the struct BlockCache with methods, start and get_block.

As soon as the method start is called, a blockfile is read into memory and 

I use HashMap to represent the block file data in memory directly, The SipHash function used by Rust in it's HashMap implementation even with million entries has low probability of collisions.

From the Birthday problem, used to calculate probability of collisions:

![equation](https://latex.codecogs.com/svg.latex?P(\text{collision})%20\approx%201%20-%20e^{-\frac{n(n-1)}{2M}})


M=64 since SipHash is 64 bit hash and for n = 1000000, we get 2.7×10−6 as the probability of collisions.

The only concern is lack of cache locality but it should start becoming a significant factor at sizes bigger than the one assumed now.

That requires a different solution to the one presented above and I would love to implement if asked.


